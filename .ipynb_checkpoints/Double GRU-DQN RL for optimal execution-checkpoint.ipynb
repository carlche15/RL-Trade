{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952b8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handlers import StockHistDataHandler,ComputeSuite\n",
    "from trade_env_v0 import trade_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163cf48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "from scipy.stats import norm, uniform\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%config Completer.use_jedi = False\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, GRU, TimeDistributed, Input, Masking\n",
    "\n",
    "from utilities.function_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ad310",
   "metadata": {},
   "source": [
    "# Data Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa0c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = StockHistDataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60572aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_range = [\"2019-01-15\",\"2021-07-5\"]\n",
    "raw_data = data_handler.get_data(sql= \"\"\"SELECT * from intraday_hist WHERE CAST([eff_date] as time) > \n",
    "CAST('9:30' as time) and CAST([eff_date] as time) < CAST('15:30' as time) and ticker='FB' order by eff_date asc\"\"\")\n",
    "# _ = ComputeSuite.pct_return(all_data.loc[:,:,:])\n",
    "# raw_price_data= raw_data.loc[:,[\"adj_close_price\"],:]\n",
    "raw_p_v_data = raw_data.loc[:,[\"adj_close_price\",\"volume\"],:]\n",
    "raw_p_v_data = np.moveaxis(raw_p_v_data.values, [0,1],[1,0])\n",
    "train_data = raw_p_v_data[:,:,~np.isnan(raw_p_v_data.sum(axis=0)[0])]\n",
    "# train_data = train_data[::-1,:,:] # trading of snapchat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba12f4",
   "metadata": {},
   "source": [
    "\n",
    "# Main & Target network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6384e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def state_sampler(state_hist_buffer, indices):\n",
    "    \"\"\"\n",
    "    given state history buffer and sample indices, return the data in the model input format\n",
    "    \"\"\"\n",
    "    sampled_time_series = np.concatenate([state_hist_buffer[i][0] for i in indices],axis=0)\n",
    "    sampled_current = np.concatenate([state_hist_buffer[i][1] for i in indices],axis=0)\n",
    "    return [sampled_time_series,sampled_current]\n",
    "\n",
    "def trade_model():\n",
    "    \n",
    "    ### timeseries sub_network\n",
    "    input_layer = keras.layers.Input(shape=(None,2,))\n",
    "    hidden_layer = keras.layers.GRU(20, activation=\"tanh\",return_sequences = True, name=\"gru1\")(input_layer)\n",
    "    hidden_layer = keras.layers.GRU(20, activation = \"tanh\", return_sequences =False, name = \"gru2\")(hidden_layer)\n",
    "    output_layer = keras.layers.Dense(2, activation=\"relu\", name =\"dense2\")(hidden_layer)\n",
    "    \n",
    "    \n",
    "    ### higher level vinalla neural network\n",
    "    input2 = keras.layers.Input(shape = (3))\n",
    "    concat = keras.layers.Concatenate()([output_layer, input2])\n",
    "    h2 = keras.layers.Dense(20,activation = \"relu\")(concat)\n",
    "    h2 = keras.layers.Dense(20,activation = \"relu\")(h2)\n",
    "    h2 = keras.layers.Dense(20,activation = \"relu\")(h2)\n",
    "    h2 = keras.layers.Dense(20,activation = \"relu\")(h2)\n",
    "    out2 = keras.layers.Dense(5, activation = \"linear\")(h2)\n",
    "     \n",
    "    model = keras.Model(inputs = [input_layer, input2], outputs = [out2])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1635d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, None, 20)     1440        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 20)           2520        gru1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 2)            42          gru2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5)            0           dense2[0][0]                     \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 20)           120         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20)           420         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 20)           420         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5)            105         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,487\n",
      "Trainable params: 5,487\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "main_model = trade_model()\n",
    "target_model = trade_model()\n",
    "main_model.summary()\n",
    "tf.keras.utils.plot_model(\n",
    "    main_model, to_file='model.png', show_shapes=True,\n",
    "    show_layer_names=True, rankdir='TB', expand_nested=True, dpi=60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb5f72",
   "metadata": {},
   "source": [
    "# Hyper/Macro settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9856412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss_function = keras.losses.Huber() # Huber goes to town!\n",
    "# optimizer = keras.optimizers.Adam(learning_rate= 0.0000250,clipnorm=1.0)\n",
    "# optimizer = keras.optimizers.RMSprop(learning_rate= 0.00015)\n",
    "\n",
    "\n",
    "\n",
    "##### DQN RL Hyper-parameters #######\n",
    "start_ep = 0\n",
    "num_episode = 120000\n",
    "update_target = 32    # update target network every # steps\n",
    "gamma = 1   # reward decay\n",
    "# episode_idx = 0 # turned off\n",
    "exploring_state_boundary = 5000 # 1. explore boundary, 2. explore sub optimal\n",
    "exploring_state_sub_opt = 10000\n",
    "num_of_action = 5   # number of action is limited to sell 0,1,2,3,4 shares per minute\n",
    "epsilon = 0.1  # exploration geedy parameter\n",
    "prob_of_smaller_interval = 0.3 # greedy parameter for smaller scenario\n",
    "time_elapsed = 0 # starting index, careful with this!\n",
    "\n",
    "oversale_punish = 0.005\n",
    "reward_curve = []\n",
    "TWAP = []\n",
    "model_average = []\n",
    "\n",
    "\n",
    "\n",
    "##### Replay-buffer Hyper-parameters #######\n",
    "max_buffer_length = 10000    \n",
    "action_history = []\n",
    "reward_history = []\n",
    "state_history = []\n",
    "state_next_history = []\n",
    "done_history = []\n",
    "update_after_action = 4\n",
    "batch_size = 64\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# ########## learning rates\n",
    "\n",
    "# step = tf.Variable(0, trainable=False)\n",
    "# boundaries = [exploring_state_boundary, exploring_state_sub_opt]\n",
    "# values = [0.006, 0.003, 0.0001]\n",
    "# learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "#     boundaries, values)\n",
    "# learning_rate = learning_rate_fn(step)\n",
    "# optimizer = keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "\n",
    "\n",
    "###\n",
    "optimizer = keras.optimizers.Adam(learning_rate= 0.00005,clipnorm=1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281be29",
   "metadata": {},
   "source": [
    "# Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26e3b750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x000002C182332070>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"C:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 4354, in <genexpr>\n",
      "    ta.write(time, out) for ta, out in zip(output_ta_t, flat_output))  File \"C:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 247, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x000002C184E28C10>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"C:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 4354, in <genexpr>\n",
      "    ta.write(time, out) for ta, out in zip(output_ta_t, flat_output))  File \"C:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 247, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "previous_model = keras.models.load_model(\"onlygoodone2\")\n",
    "\n",
    "main_model.set_weights(previous_model.get_weights())\n",
    "target_model.set_weights(previous_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9268c565",
   "metadata": {},
   "source": [
    "### Examine base model if you will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d6d1d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4640391e-05, 3.8236938e-04, 3.3223070e-04, 4.5272522e-04,\n",
       "        1.0121614e-04]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep = 10022\n",
    "random_idx = 1290\n",
    "\n",
    "env = trade_env(data = train_data[:,:,random_idx+1:]/train_data[:,:,random_idx+20,None])\n",
    "# env.current_price= \n",
    "# env.inventory = 7\n",
    "# env.time_remain = 7\n",
    "state1 = env.start()\n",
    "main_model.predict(state1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef224cd",
   "metadata": {},
   "source": [
    "# Train double GRU-DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "431e8a0b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training from ep 10000\n",
      "10000\n",
      "avg_reward:  -1.3424669698466627e-05 10001\n",
      "10100\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x000002C185AEA4F0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"C:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 4354, in <genexpr>\n",
      "    ta.write(time, out) for ta, out in zip(output_ta_t, flat_output))  File \"C:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 247, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "10400\n",
      "avg_reward:  1.0040533451448663e-05 10001\n",
      "10500\n",
      "10600\n",
      "avg_reward:  9.138510730418697e-06 10001\n",
      "10800\n",
      "avg_reward:  1.0862077395317093e-05 10001\n",
      "10900\n",
      "11000\n",
      "avg_reward:  1.2150553439153857e-05 10001\n",
      "11200\n",
      "avg_reward:  1.3791144459330061e-05 10001\n",
      "11300\n",
      "11400\n",
      "avg_reward:  2.3352132600103433e-05 10001\n",
      "11600\n",
      "avg_reward:  2.9736767162708517e-05 10001\n",
      "11700\n",
      "11800\n",
      "avg_reward:  3.15607968771368e-05 10001\n",
      "11900\n",
      "12300\n",
      "12400\n",
      "avg_reward:  3.075472280115582e-05 10001\n",
      "13100\n",
      "13300\n",
      "13400\n",
      "avg_reward:  5.6320347637648644e-05 10001\n",
      "13500\n",
      "13600\n",
      "avg_reward:  5.2784201400962254e-05 10001\n",
      "13700\n",
      "14000\n",
      "avg_reward:  5.1640139947106584e-05 10001\n",
      "14300\n",
      "14600\n",
      "avg_reward:  1.9161698179809453e-05 10001\n",
      "14700\n",
      "15100\n",
      "15800\n",
      "avg_reward:  9.387496553543363e-06 10001\n",
      "16500\n",
      "16700\n",
      "16900\n",
      "17000\n",
      "avg_reward:  1.276118707668821e-05 10001\n",
      "17100\n",
      "17300\n",
      "17600\n",
      "avg_reward:  2.7239834825175482e-06 10001\n",
      "18000\n",
      "avg_reward:  -1.4625084703008679e-05 10001\n",
      "18200\n",
      "avg_reward:  -3.198686046383123e-05 10001\n",
      "18400\n",
      "avg_reward:  -1.938602253183541e-05 10001\n",
      "18500\n",
      "18900\n",
      "19100\n",
      "19500\n",
      "19700\n",
      "19900\n",
      "20000\n",
      "avg_reward:  3.026065893840315e-07 10001\n",
      "20100\n",
      "20200\n",
      "avg_reward:  -1.7796698968524316e-05 10001\n",
      "20300\n",
      "20700\n",
      "20900\n",
      "21000\n",
      "avg_reward:  -6.272514185230184e-05 10001\n",
      "21100\n",
      "21300\n",
      "21400\n",
      "avg_reward:  -8.498239012918969e-05 10001\n",
      "22000\n",
      "avg_reward:  -0.00010884436715109656 10001\n",
      "22200\n",
      "avg_reward:  -0.00012575599386475747 10001\n",
      "22500\n",
      "22600\n",
      "avg_reward:  -0.0001038860363017779 10001\n",
      "22700\n",
      "22800\n",
      "avg_reward:  -9.788058342963725e-05 10001\n",
      "23500\n",
      "23800\n",
      "avg_reward:  -0.00011412631773697718 10001\n",
      "24000\n",
      "avg_reward:  -0.00011005527361791182 10001\n",
      "24100\n",
      "24200\n",
      "avg_reward:  -0.00011099270487264258 10001\n",
      "24300\n",
      "24400\n",
      "avg_reward:  -0.00010828572491109931 10001\n",
      "24500\n",
      "24600\n",
      "avg_reward:  -9.117192523067335e-05 10001\n",
      "24700\n",
      "24800\n",
      "avg_reward:  -7.592405530654824e-05 10001\n",
      "24900\n",
      "25400\n",
      "avg_reward:  -3.761746544719949e-05 10001\n",
      "25600\n",
      "avg_reward:  -3.2086176352836716e-05 10001\n",
      "26100\n",
      "26200\n",
      "avg_reward:  1.0305574555002457e-06 10001\n",
      "26300\n",
      "26500\n",
      "26900\n",
      "27000\n",
      "avg_reward:  8.006065861442228e-06 10001\n",
      "27100\n",
      "27500\n",
      "28000\n",
      "avg_reward:  1.9335351678976675e-05 10001\n",
      "28100\n",
      "28500\n",
      "28700\n",
      "29000\n",
      "avg_reward:  4.340460421893762e-07 10001\n",
      "29100\n",
      "29200\n",
      "avg_reward:  -1.5644467038864926e-05 10001\n",
      "29500\n",
      "29600\n",
      "avg_reward:  -3.58202534164445e-05 10001\n",
      "29800\n",
      "avg_reward:  -3.835461738550025e-05 10001\n",
      "29900\n",
      "30000\n",
      "avg_reward:  -3.776927411468346e-05 10001\n",
      "30400\n",
      "avg_reward:  -1.3698100581027619e-05 10001\n",
      "30500\n",
      "30600\n",
      "avg_reward:  -2.6175851794147805e-06 10001\n",
      "30900\n",
      "31000\n",
      "avg_reward:  1.712878292412418e-05 10001\n",
      "31100\n",
      "31400\n",
      "avg_reward:  2.2993050731480406e-05 10001\n",
      "31500\n",
      "31900\n",
      "32000\n",
      "avg_reward:  3.6241002580205656e-05 10001\n",
      "32100\n",
      "32400\n",
      "avg_reward:  1.939495593676472e-05 10001\n",
      "32500\n",
      "32800\n",
      "avg_reward:  3.738980831215997e-05 10001\n",
      "33100\n",
      "33200\n",
      "avg_reward:  1.107822912784746e-05 10001\n",
      "33400\n",
      "avg_reward:  1.9634732443664875e-05 10001\n",
      "33600\n",
      "avg_reward:  1.2474608309684374e-05 10001\n",
      "33700\n",
      "33900\n",
      "34000\n",
      "avg_reward:  3.0051905839388546e-06 10001\n",
      "34100\n",
      "34200\n",
      "avg_reward:  2.93919063091674e-07 10001\n",
      "34800\n",
      "avg_reward:  -1.651682665382508e-05 10001\n",
      "35000\n",
      "avg_reward:  -2.394380871860481e-05 10001\n",
      "35700\n",
      "35800\n",
      "avg_reward:  -3.052080469629467e-05 10001\n",
      "35900\n",
      "36400\n",
      "avg_reward:  -3.44514970065123e-05 10001\n",
      "36500\n",
      "36600\n",
      "avg_reward:  -1.7647143565629924e-05 10001\n",
      "37100\n",
      "37200\n",
      "avg_reward:  -2.313854740412242e-06 10001\n",
      "37300\n",
      "37700\n",
      "37900\n",
      "38000\n",
      "avg_reward:  7.049199440416084e-07 10001\n",
      "38200\n",
      "avg_reward:  1.0110481701368128e-05 10001\n",
      "38400\n",
      "avg_reward:  1.970581740968173e-06 10001\n",
      "38500\n",
      "38900\n",
      "39000\n",
      "avg_reward:  6.014565025843839e-06 10001\n",
      "39100\n",
      "39200\n",
      "avg_reward:  -2.155589982990077e-06 10001\n",
      "39400\n",
      "avg_reward:  -1.049383839953795e-05 10001\n",
      "39500\n",
      "39700\n",
      "39800\n",
      "avg_reward:  -1.4447041747789203e-05 10001\n",
      "40000\n",
      "avg_reward:  -2.618727919866808e-05 10001\n",
      "40100\n",
      "40200\n",
      "avg_reward:  -3.933554780529972e-05 10001\n",
      "40300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-921af89afad4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m--> 385\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    386\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    438\u001b[0m       \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_RUNTIME_UNKNOWN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0m\u001b[0;32m    441\u001b[0m           inputs, initial_state, training, mask, row_lengths)\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[1;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mlast_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpu_gru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mgpu_gru_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[0mlast_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandard_gru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnormal_gru_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m       last_output, outputs, new_h, runtime = gru_with_backend_selection(\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_gru\u001b[1;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m   last_output, outputs, new_states = K.rnn(\n\u001b[0m\u001b[0;32m    576\u001b[0m       \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m       \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minit_h\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4358\u001b[1;33m       final_outputs = control_flow_ops.while_loop(\n\u001b[0m\u001b[0;32m   4359\u001b[0m           \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4360\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2733\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2734\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2735\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2736\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2737\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[0;32m   4342\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mta\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_ta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4343\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4344\u001b[1;33m         output, new_states = step_function(current_input,\n\u001b[0m\u001b[0;32m   4345\u001b[0m                                            tuple(states) + tuple(constants))\n\u001b[0;32m   4346\u001b[0m         \u001b[0mflat_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;31m# inputs projected by all gate matrices at once\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[0mmatrix_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m     \u001b[0mmatrix_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[0mx_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(x, bias, data_format)\u001b[0m\n\u001b[0;32m   5771\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5772\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NCHW'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5773\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5774\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5775\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   3364\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3366\u001b[1;33m       return gen_nn_ops.bias_add(\n\u001b[0m\u001b[0;32m   3367\u001b[0m           value, bias, data_format=data_format, name=name)\n\u001b[0;32m   3368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m    673\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    676\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BiasAdd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         tld.op_callbacks, value, bias, \"data_format\", data_format)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_ep = 10000\n",
    "\n",
    "print(f\"Training from ep {start_ep}\")\n",
    "for ep in range(start_ep, num_episode+start_ep):\n",
    "    \n",
    "    \n",
    "    ######## 1. training cache  ############\n",
    "\n",
    "    episode_reward = []\n",
    "    \n",
    "\n",
    "    ######## 2. load environment  ############\n",
    "    \n",
    "    random_idx = np.random.randint(low=1, high = 160000) # sample from environment   \n",
    "    data_slice =  train_data[:,:,random_idx+1:] #/train_data[:,:,random_idx+20,None] # todo: +20 is hard coded to normalize the trade start pric\n",
    "    \n",
    "    max_price_chg = np.max(np.abs(np.diff(data_slice[0,0,:32]))) # take out extreme environment (price pattern)\n",
    "    max_volume_chg = np.max(np.abs(np.diff(data_slice[1,0,:32])))# take out extreme environment (volume pattern)\n",
    "    if max_price_chg>0.5 or max_volume_chg>55000: # tody criteria hard coded for SNAP\n",
    "        continue \n",
    "        \n",
    "    data_slice_normalized = train_data[:,:,random_idx+1:] /train_data[:,:,random_idx+20,None]   \n",
    "    env = trade_env(data =data_slice_normalized) # initialized environment\n",
    "    \n",
    "    ######## 3.1 modify environment for small episode exploration ############\n",
    "    # at begining stage of training or later statge with certain probability, modify the remaining time \n",
    "    # for the episode (make it very small)\n",
    "    if prob_of_smaller_interval>np.random.rand(1)[0] or ep<exploring_state_boundary: #   \n",
    "        env.time_remain = np.random.choice([2,3,4])\n",
    "    else:\n",
    "        env.time_remain = 10\n",
    "        \n",
    "    current_state = env.start()\n",
    "    is_full_episode = True if env.time_remain ==10 else False\n",
    "    \n",
    "    \n",
    "    ######## 3.2 exploration-stage and epsilon greedy  ############\n",
    "    # at begining stage of training or later statge with certain probability, take sub-optimal actions \n",
    "    while True:\n",
    "        time_elapsed+=1\n",
    "        if time_elapsed%update_target ==0:\n",
    "                target_model.set_weights(main_model.get_weights())\n",
    "     \n",
    "        if ep< exploring_state_sub_opt or epsilon>np.random.rand(1)[0]:\n",
    "            action = np.random.choice(num_of_action)\n",
    "           \n",
    "        else:\n",
    "            action = tf.argmax(main_model(current_state,training = False),axis=1).numpy()[0]\n",
    "            \n",
    "           \n",
    "        ####### 4 take actions/save experience to reply buffer  ############\n",
    "        \n",
    "        next_state, reward, end_episode = env.step(action)\n",
    "        action_history.append(action)\n",
    "        reward_history.append(reward)\n",
    "        state_history.append(current_state)\n",
    "        state_next_history.append(next_state)\n",
    "        done_history.append(end_episode)\n",
    "        episode_reward.append(reward)\n",
    "        \n",
    "        ######## 5 train in the experience-replay buffer  ############\n",
    "        \n",
    "        if  len(action_history)>= batch_size and time_elapsed%update_after_action==0:\n",
    "            \n",
    "        \n",
    "            indices = np.random.choice(np.arange(len(action_history)),batch_size) # sample # of record from buffer\n",
    "            state_sample = state_sampler(state_history, indices) # sample state (both current and time series) with sate_sampler function\n",
    "            state_next_sample = state_sampler(state_next_history, indices)\n",
    "            reward_sample = np.array(reward_history)[indices]\n",
    "            action_sample = np.array(action_history)[indices]\n",
    "            done_sample = np.array(done_history)[indices]\n",
    "\n",
    "            future_state_action_val = target_model.predict(state_next_sample)\n",
    "            future_state_action_val[np.isnan(future_state_action_val)] = 0 # this is for the terminal state (nans)\n",
    "            future_reward = tf.reduce_max(future_state_action_val,axis=1)\n",
    "         \n",
    "            G = reward_sample+gamma*future_reward #compute \"True\" future reward based on model (bootstrapped)\n",
    "            mask = tf.one_hot(action_sample,num_of_action) # only train on the actions that are chosen\n",
    "      \n",
    "           \n",
    "#             print(f\"Act pre:{tf.reduce_sum(tf.multiply(main_model(state_sample),mask),axis=1)}\")\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Hijack gradient and customize the training process\n",
    "                \n",
    "                current_state_action_val = main_model(state_sample)\n",
    "                current_reward = tf.reduce_sum(tf.multiply(current_state_action_val,mask),axis=1) # compute \"Model\" future reward\n",
    "                loss = loss_function(G, current_reward)  \n",
    "            grad = tape.gradient(loss, main_model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grad, main_model.trainable_variables))\n",
    "         \n",
    "#             print(f\"Act target:{G}\")\n",
    "#             print(f\"Act post:{tf.reduce_sum(tf.multiply(main_model(state_sample),mask),axis=1)}\")\n",
    "\n",
    "                \n",
    "                \n",
    "        ######## 6. set_state, clear buffer, and end episode  ############\n",
    "\n",
    "        current_state = next_state\n",
    "        if len(action_history)>max_buffer_length:\n",
    "            del action_history[:1]\n",
    "            del state_history[:1]\n",
    "            del state_next_history[:1]\n",
    "            del done_history[:1]\n",
    "            del reward_history[:1]\n",
    "        \n",
    "        \n",
    "        if end_episode:\n",
    "            \n",
    "            TWAP.append(env.TWAP)\n",
    "            model_average.append(env.average_trade_price)\n",
    "            if ep%100 ==0:\n",
    "                print(ep)\n",
    "            if ep%200==0:\n",
    "                print(\"avg_reward: \",np.mean(reward_history),len(reward_history))\n",
    "                \n",
    "            \n",
    "            break\n",
    " \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6a276",
   "metadata": {},
   "source": [
    "# Test double GRU-DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d3d7af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### fixed version\n",
    "\n",
    "TWAP_test = []\n",
    "model_average_test = []\n",
    "for ep in range(5000):\n",
    "    \n",
    "    \n",
    "    ######## training cache  ############\n",
    "    ######################################\n",
    "\n",
    "    episode_reward = []\n",
    "\n",
    "    ######## load episode data ############\n",
    "    ######################################\n",
    "    random_idx = np.random.randint(low=1, high = 160000)\n",
    "    \n",
    "    data_slice =  train_data[:,:,random_idx+1:] #/train_data[:,:,random_idx+20,None] # todo: +20 is hard coded to normalize the trade start pric\n",
    "    max_price_chg = np.max(np.abs(np.diff(data_slice[0,0,:32])))\n",
    "    max_volume_chg = np.max(np.abs(np.diff(data_slice[1,0,:32])))\n",
    "    if max_price_chg>0.5 or max_volume_chg>55000:\n",
    "        continue\n",
    "    data_slice_normalized = train_data[:,:,random_idx+1:] /train_data[:,:,random_idx+20,None]\n",
    "        \n",
    "    env = trade_env(data =data_slice_normalized)\n",
    "    ######## modify environment for small episode exploration ############\n",
    "    ######################################################################\n",
    "    if prob_of_smaller_interval>np.random.rand(1)[0]:  \n",
    "        env.time_remain = np.random.choice([2,3,4])\n",
    "    else:\n",
    "        env.time_remain = 10\n",
    "        \n",
    "    current_state = env.start()\n",
    "    is_full_episode = True if env.time_remain ==10 else False\n",
    "     \n",
    "    ######## exploration-stage and epsilon greedy  ############\n",
    "    ##########################################################\n",
    "    while True:\n",
    "        \n",
    "\n",
    "        action = tf.argmax(main_model(current_state,training = False),axis=1).numpy()[0]\n",
    "        print(action) # , main_model(current_state,training = False))\n",
    "            \n",
    "        next_state, reward, end_episode = env.step(action)\n",
    "        current_state = next_state\n",
    "      \n",
    "        \n",
    "        if end_episode:\n",
    "            print(f\"########{ep}##########\")\n",
    "            \n",
    "            TWAP_test.append(env.TWAP)\n",
    "            model_average_test.append(env.average_trade_price)\n",
    "         \n",
    "                \n",
    "            break\n",
    " \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a26ff1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
