{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952b8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handlers import StockHistDataHandler,ComputeSuite\n",
    "from trade_env_v0 import trade_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163cf48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "from scipy.stats import norm, uniform\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%config Completer.use_jedi = False\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, GRU, TimeDistributed, Input, Masking\n",
    "\n",
    "from utilities.function_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa0c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = StockHistDataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60572aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_range = [\"2019-01-15\",\"2021-07-5\"]\n",
    "raw_data = data_handler.get_data(sql= \"\"\"SELECT * from intraday_hist WHERE CAST([eff_date] as time) > CAST('9:30' as time) and CAST([eff_date] as time) < CAST('15:30' as time) order by eff_date asc\"\"\")\n",
    "# _ = ComputeSuite.pct_return(all_data.loc[:,:,:])\n",
    "raw_data = raw_data.loc[:,[\"adj_close_price\"],:]\n",
    "train_data = raw_data.values[:,:,~np.isnan(raw_data.values.sum(axis=0)[0])]\n",
    "train_data = train_data[::-1,:,:] # trading of snapchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6384e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def state_sampler(state_hist_buffer, indices):\n",
    "    \"\"\"\n",
    "    given state history buffer and sample indices, return the data in the model input format\n",
    "    \"\"\"\n",
    "    sampled_time_series = np.concatenate([state_hist_buffer[i][0] for i in indices],axis=0)\n",
    "    sampled_current = np.concatenate([state_hist_buffer[i][1] for i in indices],axis=0)\n",
    "    return [sampled_time_series,sampled_current]\n",
    "\n",
    "def trade_model():\n",
    "    \n",
    "    ### timeseries sub_network\n",
    "    input_layer = keras.layers.Input(shape=(None,5,))\n",
    "    hidden_layer = keras.layers.GRU(20, activation=\"tanh\",return_sequences = True, name=\"gru1\")(input_layer)\n",
    "    hidden_layer = keras.layers.GRU(20, activation = \"tanh\", return_sequences =False, name = \"gru2\")(hidden_layer)\n",
    "    output_layer = keras.layers.Dense(2, activation=\"relu\", name =\"dense2\")(hidden_layer)\n",
    "    \n",
    "    \n",
    "    ### higher level vinalla neural network\n",
    "    input2 = keras.layers.Input(shape = (3))\n",
    "    concat = keras.layers.Concatenate()([output_layer, input2])\n",
    "    h2 = keras.layers.Dense(20,activation = \"relu\")(concat)\n",
    "    h2 = keras.layers.Dense(20,activation = \"relu\")(h2)\n",
    "    h2 = keras.layers.Dense(20,activation = \"relu\")(h2)\n",
    "    h2 = keras.layers.Dense(20,activation = \"relu\")(h2)\n",
    "    out2 = keras.layers.Dense(5, activation = \"linear\")(h2)\n",
    "     \n",
    "    model = keras.Model(inputs = [input_layer, input2], outputs = [out2])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9856412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "main_model = trade_model()\n",
    "target_model = trade_model()\n",
    "loss_function = keras.losses.Huber() #Huber()\n",
    "# optimizer = keras.optimizers.Adam(learning_rate= 0.0000250,clipnorm=1.0)\n",
    "# optimizer = keras.optimizers.RMSprop(learning_rate= 0.00015)\n",
    "# main_model.summary()\n",
    "# tf.keras.utils.plot_model(\n",
    "#     main_model, to_file='model.png', show_shapes=True,\n",
    "#     show_layer_names=True, rankdir='TB', expand_nested=True, dpi=60\n",
    "# )\n",
    "\n",
    "start_ep = 10000\n",
    "num_episode = 100000\n",
    "update_target = 128\n",
    "gamma = 1\n",
    "epi_sode_idx = 0\n",
    "exploring_state_boundary = 5000 # 1. explore boundary, 2. explore sub optimal\n",
    "exploring_state_sub_opt = 10000\n",
    "num_of_action = 5\n",
    "epsilon = 0.2\n",
    "prob_of_smaller_interval = 0.3\n",
    "time_elapsed = 0\n",
    "\n",
    "oversale_punish = 0.005\n",
    "reward_curve = []\n",
    "TWAP = []\n",
    "model_average = []\n",
    "\n",
    "\n",
    "\n",
    "# replay_buffer\n",
    "max_buffer_length = 20000\n",
    "action_history = []\n",
    "reward_history = []\n",
    "state_history = []\n",
    "state_next_history = []\n",
    "done_history = []\n",
    "update_after_action = 4\n",
    "batch_size = 32\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# ########## learning rates\n",
    "# optimizer = keras.optimizers.RMSprop(learning_rate= 0.0001)\n",
    "# step = tf.Variable(0, trainable=False)\n",
    "# boundaries = [exploring_state_boundary, exploring_state_sub_opt]\n",
    "# values = [0.006, 0.003, 0.0002]\n",
    "# learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "#     boundaries, values)\n",
    "# learning_rate = learning_rate_fn(step)\n",
    "# optimizer = keras.optimizers.RMSprop(learning_rate= learning_rate)\n",
    "optimizer = keras.optimizers .Adam(learning_rate= 0.00001,clipnorm=1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281be29",
   "metadata": {},
   "source": [
    "# load previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3338567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "previous_model = keras.models.load_model(\"13k_trace3\")\n",
    "main_model.set_weights(previous_model.get_weights())\n",
    "target_model.set_weights(previous_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d6d1d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[810.8856 , 710.37836, 615.6319 , 531.71643, 444.48364]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep = 10022\n",
    "random_idx = 1000\n",
    "env = trade_env(data = train_data[:,:,random_idx+1:]/train_data[:,:,random_idx+20,None])\n",
    "env.inventory = 100\n",
    "env.time_remain = 10\n",
    "state1 = env.start()\n",
    "main_model.predict(state1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82a1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6915f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe7bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "431e8a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training from ep 0\n",
      "tf.Tensor(\n",
      "[  0.      412.05908 607.46356 702.77155 888.7391  876.5939  814.71844\n",
      " 698.03      0.        0.      507.35437   0.      698.12396 557.4443\n",
      " 888.7127  619.4642    0.        0.      686.0551  479.11487   0.\n",
      " 619.4435  288.28455 702.7557  698.08624 226.09573 602.67755   0.\n",
      "   0.      624.08765   0.      176.1194 ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[478.82672 814.7562  478.46942   0.      524.0954    0.      495.3302\n",
      " 507.38983 461.81543   0.      910.0109  126.17084 192.80696 507.33685\n",
      " 624.0185  590.7378    0.      507.48944  73.62148 304.91876   0.\n",
      "   0.        0.      698.0294  209.45688 624.03906   0.      719.4426\n",
      "   0.        0.      905.43195 910.15717], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[619.2847    0.      781.4449  602.73956 623.9923  271.32886 719.3889\n",
      " 607.44257 416.76788   0.        0.        0.      893.5368    0.\n",
      " 221.37572 159.33406 602.70575 669.45496 304.69086 590.9157  702.6586\n",
      "   0.        0.        0.      607.55927 698.05133 321.5299  714.47687\n",
      " 287.94086 523.9998  893.39264   0.     ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[ 910.03766   416.7459    221.773       0.        624.0535    798.1206\n",
      " 1005.3641      0.          0.          0.          0.        602.69617\n",
      "    0.        507.2683    814.7005     73.62506     0.        798.08014\n",
      "  798.181     624.0539      0.          0.        905.37964   698.11285\n",
      "  814.71967   400.06287   495.4148     97.280426    0.        905.42035\n",
      "    0.        221.5092  ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.       66.87778 416.5531    0.        0.      607.39124 288.13727\n",
      " 574.13837 719.3889    0.      512.1017  698.0889    0.      797.97473\n",
      "   0.      524.09625 399.96027 524.1285    0.        0.      304.75024\n",
      "   0.      176.1002  221.16891 316.6595    0.      793.382   905.27924\n",
      " 697.9693    0.      383.4427  192.6455 ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.      698.0928    0.        0.      316.77698   0.      909.94745\n",
      " 607.41345   0.      495.46246 590.80133   0.      714.6818  798.0527\n",
      "   0.      590.7393  321.39905 698.2243  304.73212 798.14935 888.6696\n",
      " 698.077     0.        0.      702.7955    0.        0.        0.\n",
      " 888.7127  702.8251    0.        0.     ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[ 607.32465    0.         0.       411.85052  507.41425  304.641\n",
      "   97.47183    0.         0.       524.0783  1005.3435     0.\n",
      "  810.04895  416.64545  893.2305   624.0539     0.       698.05524\n",
      "  495.50513  793.4443     0.       411.95703    0.      1005.3811\n",
      "  972.05255  719.3315   383.23486  507.46448  793.49664    0.\n",
      "  590.76776    0.     ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[288.1325    0.      602.6253    0.      607.40546   0.        0.\n",
      "  82.34889 524.0567  719.2437    0.      383.67346 209.7217    0.\n",
      "   0.        0.      697.97577 719.35504 507.41138 798.0539  905.4301\n",
      " 876.6975  702.7398    0.        0.        0.        0.        0.\n",
      "   0.        0.        0.      304.73218], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[719.57074 910.06647 619.38715 607.1032  698.07745 574.0614  159.32799\n",
      "   0.      624.05817 814.6769  702.722   412.065   719.54816 366.67786\n",
      "   0.        0.        0.      412.04297 316.6454    0.      686.36444\n",
      "   0.        0.      288.10217 523.99695   0.      254.96771 876.76697\n",
      "   0.      814.7779  910.08344   0.     ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[   0.       702.7432   702.6528     0.       876.7166    66.89578\n",
      "  590.4262  1005.36646   97.54689  814.6995   209.3402   602.6144\n",
      "   73.67425  686.0455     0.       495.474    619.3515     0.\n",
      "  814.73     719.3889     0.       910.0059     0.       698.06726\n",
      "  383.55566    0.         0.      1005.4371   304.7152   888.77783\n",
      "  602.8609     0.     ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[607.46344  798.0733   910.0716     0.       495.45947  719.4051\n",
      " 271.39862  176.06767    0.       602.6485   781.33246  624.00336\n",
      "   0.       619.371    159.15053    0.       719.36176    0.\n",
      " 524.079    624.05817  512.0605     0.       366.67468    0.\n",
      " 271.4082    73.553444 221.37317    0.       793.382    113.982925\n",
      "   0.       619.3875  ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[698.1314  719.5204  192.70052 478.6394  507.41724   0.        0.\n",
      " 411.97986 602.81726   0.        0.      478.7093  793.382     0.\n",
      " 176.01025 910.18024   0.      702.86676 590.78723 495.36932 366.89252\n",
      "   0.      719.3419    0.        0.      495.3573  623.91785 512.1574\n",
      " 574.00305 192.55058 507.48254 619.5307 ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.      192.75365   0.      793.44507   0.      619.3875  416.7298\n",
      "   0.        0.      590.8479    0.      624.05096   0.        0.\n",
      "   0.      698.0017    0.      624.0783  781.3869  524.1222  702.6423\n",
      " 793.52155 590.55725 511.8308    0.      781.4078  905.2986  428.86224\n",
      " 619.3875  411.99976 719.4012  366.5915 ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[221.41133   66.904236   0.       254.82964  507.23053    0.\n",
      " 781.3222   511.98175    0.       810.0267   793.315    669.45496\n",
      " 814.7604   142.71588  507.24213  798.189      0.         0.\n",
      " 400.12848  254.64143    0.       814.53674  461.93274    0.\n",
      " 507.2975   114.       495.4652     0.         0.         0.\n",
      " 316.6479   126.230034], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[714.71826  478.661      0.         0.         0.       288.24713\n",
      " 607.427      0.        66.900894 719.3415   714.6828   209.40147\n",
      "   0.         0.         0.       412.0218   702.6148   512.0249\n",
      " 624.0152     0.       619.2981   524.0567     0.       719.4909\n",
      "   0.       524.1082   623.9477   209.34435  669.4737     0.\n",
      "   0.         0.      ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[602.721    814.6866     0.       416.69458   82.295654 366.77277\n",
      " 810.1054   512.0815   702.6621   607.32294  797.88794  607.3365\n",
      " 209.50127  698.05133  159.49377  905.2891   175.98767    0.\n",
      " 507.41272  349.87067  304.7751     0.         0.         0.\n",
      "   0.       910.11176  176.04063    0.       175.99146  316.73535\n",
      "   0.       192.84453 ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[797.9865   910.0778     0.        97.722626 192.76692  602.69904\n",
      " 698.17737    0.         0.         0.         0.        97.40384\n",
      "   0.       512.01855  719.42     988.6066     0.       719.415\n",
      " 383.4165   192.7588     0.         0.       814.7424     0.\n",
      " 416.7135     0.         0.         0.         0.       719.42535\n",
      "   0.         0.      ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[ 192.717      0.       905.3174   254.67445  288.04718    0.\n",
      "    0.       814.7677   400.06555   97.4377   685.82214  624.1081\n",
      "  859.9628   126.01659    0.         0.       366.67786  114.11629\n",
      "    0.         0.         0.       714.66943    0.       461.79913\n",
      "  512.0876     0.      1005.3909   702.82086    0.         0.\n",
      "  697.9742   512.11786], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[719.4336  698.0317  624.0243    0.      607.4255  702.722   495.53693\n",
      "   0.       66.88952 909.9317  573.978     0.      495.77057 798.29706\n",
      " 237.59055 624.0321  507.4242    0.      798.0213    0.      719.2993\n",
      " 462.0666  511.93597   0.        0.       97.42223 495.54138   0.\n",
      " 955.5019  412.0227  304.9535    0.     ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[ 607.32306   82.30624  304.79785    0.       888.72766   61.64875\n",
      "  910.08356  271.4516   176.04353  607.39703  383.33252    0.\n",
      "  602.6745   909.9693  1005.405    288.36426    0.       316.6715\n",
      " 1005.4354   793.3301   793.36804    0.       524.0567     0.\n",
      "  702.7398     0.       226.16684  304.6513   619.51294  495.43658\n",
      "  590.66644  619.37067], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[304.80957  400.06287    0.         0.         0.        82.320206\n",
      " 607.3581     0.         0.         0.       714.6172   478.79828\n",
      " 624.0445     0.       702.743     66.91292    0.         0.\n",
      " 271.41852  652.8353   590.63715  524.3697   719.418      0.\n",
      "   0.         0.       910.0712     0.       416.7298   192.87254\n",
      " 781.504    478.74048 ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.       416.82513  495.43555  495.39355  507.35767    0.\n",
      "   0.         0.       416.68298  810.21576    0.       714.78424\n",
      " 698.142      0.         0.       602.6956   793.40704    0.\n",
      "   0.       702.53174   82.378845 126.010956 126.149315 988.7715\n",
      " 719.4957   416.62134  798.0013   910.08276  524.0377   400.19086\n",
      " 607.3822     0.      ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.        0.        0.        0.      793.3442  159.38095   0.\n",
      " 607.31287 702.676     0.      495.38953 624.0719   73.69745 702.6058\n",
      " 590.6072  209.48474   0.        0.      905.3591    0.      860.1901\n",
      "   0.      512.0332  114.0637  507.4618  271.50513 624.1364    0.\n",
      "   0.      590.42847   0.      209.22917], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[690.2352   93.44548 788.3361  373.98026 596.71185   0.        0.\n",
      "   0.        0.      507.68976 864.1418    0.        0.      864.1627\n",
      " 596.6262    0.      409.4763    0.        0.      561.2266    0.\n",
      " 783.8195  881.9042   78.2385    0.      601.24493 988.6732    0.\n",
      " 770.5514    0.        0.      316.06638], shape=(32,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  0.        0.        0.      280.38287   0.      694.7809  489.87936\n",
      " 672.28796 614.4016    0.        0.        0.        0.      298.19614\n",
      " 801.539   707.9984  279.8097  298.19614 770.43445   0.        0.\n",
      " 316.01477 169.07759 766.0543  677.1013  489.77875   0.      672.5658\n",
      " 186.8972  578.9137  356.2648  895.16187], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.      707.96265 801.49445 895.1356   78.18094 262.54895   0.\n",
      "   0.        0.      396.50726   0.        0.      485.45877 561.1469\n",
      "   0.        0.      204.4517  672.49805 503.10794 881.8522  168.94305\n",
      " 391.97794   0.      690.1477    0.        0.      489.8937  489.87827\n",
      " 485.3304  409.36215 895.1356    0.     ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[485.11075    0.       596.8058     0.       676.88965  988.7296\n",
      "   0.         0.       677.1967     0.        78.18094  490.00168\n",
      " 302.5542   583.4197   690.2464   707.91614  111.150185  78.19381\n",
      "   0.         0.         0.       801.4259     0.         0.\n",
      " 485.31213  396.29648  391.6373     0.         0.       877.4131\n",
      "   0.       770.6058  ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[133.41518   0.      583.4863    0.      864.0321    0.      841.54486\n",
      " 280.44406 280.20847 543.5949  676.98083   0.      707.97327   0.\n",
      " 186.90572   0.      677.0032  391.75412 489.88922   0.        0.\n",
      "   0.        0.      881.9188  654.7129    0.      507.70355   0.\n",
      " 881.87683   0.      489.85214 204.70872], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.      801.6643  614.5375  489.8397  672.428     0.       78.14994\n",
      " 708.0488  614.4617    0.        0.      187.00893 503.14676   0.\n",
      " 895.22925   0.      988.68146 596.6785  507.68692 783.7819  489.7563\n",
      "   0.      783.743   770.6482    0.      677.0482    0.      583.3972\n",
      " 583.41693 583.5717    0.      302.77512], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.       449.82172    0.         0.         0.       298.14035\n",
      "   0.       677.01996   64.131836 708.01965  614.4808   391.79037\n",
      "   0.       988.6693     0.       507.68655    0.       338.2715\n",
      " 489.79398   78.18094  895.1654   614.4343   864.1515     0.\n",
      "   0.         0.         0.       636.87115    0.       672.3627\n",
      "   0.         0.      ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.         0.         0.       186.86375  262.45892  770.56506\n",
      " 116.04404  578.87006    0.         0.         0.        78.195145\n",
      " 708.08997  677.07117  882.0692   677.0017     0.       788.36084\n",
      " 485.33484   59.27348    0.       503.10794    0.         0.\n",
      " 578.8142   614.4823   316.05704    0.       244.37834  864.19696\n",
      " 881.9187   111.06261 ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[485.42972  766.1459   186.81834    0.       298.15384  507.80557\n",
      " 788.294    654.55457   59.214962   0.       489.94205  788.33374\n",
      " 707.9753   298.3753     0.         0.       186.85573  583.42773\n",
      " 583.4864   298.27075  690.23376  280.38126  864.1773     0.\n",
      "   0.         0.         0.       783.7875     0.       895.0768\n",
      " 895.171      0.      ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[614.55975 676.9016    0.        0.      676.8872    0.      677.0471\n",
      " 489.86765 391.51663   0.        0.      583.4686  151.42189 601.07745\n",
      "   0.      881.8773  502.88297 204.63774   0.      578.6955  485.37592\n",
      " 204.62434   0.      204.57686 280.35934 111.17461 302.7632    0.\n",
      "   0.      596.51526 298.33932 432.09317], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.        0.      396.33316   0.      770.54724   0.      801.617\n",
      "   0.      596.64606   0.      881.92725   0.        0.      614.421\n",
      " 467.53635 169.06848   0.        0.      881.9188    0.      895.146\n",
      " 449.7507  864.0885  801.58997 596.4512  690.20416 596.7704  707.98334\n",
      " 187.05058   0.        0.        0.     ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[770.8098  783.7615  801.646     0.      302.7075  677.0359    0.\n",
      " 583.54016 262.61972   0.      391.70364 841.8319    0.        0.\n",
      " 391.6901  988.6936  561.152     0.      133.37872 467.49475   0.\n",
      " 280.29697 204.50786   0.      988.7273    0.      676.9956  583.5072\n",
      "   0.      204.69896 801.68445 654.6581 ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.      864.11163 560.76    396.32983   0.        0.      244.94035\n",
      " 431.83255 485.28555 596.6101  712.7627  801.6498  489.85657   0.\n",
      "   0.        0.      654.71265   0.      204.6179  881.80664 596.64294\n",
      " 316.06564   0.      707.97876 672.46704   0.      707.98364   0.\n",
      " 409.43723   0.      614.46765   0.     ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[449.72055 783.78235 298.3666    0.        0.        0.      859.26514\n",
      " 396.33316 601.27026 864.1929  578.76404 672.45306 690.2398    0.\n",
      " 881.9589  507.68692 391.94955 676.9741  614.4437  111.07516 614.473\n",
      " 373.93784   0.      801.60474 877.5067   93.35413 707.97327 116.14942\n",
      " 801.6597  316.01346 707.95264   0.     ], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[596.7492  489.85303 690.2239  209.27588   0.      770.6023  690.10364\n",
      "  70.8902    0.      765.92847 507.73825   0.        0.      788.24915\n",
      " 988.73193   0.        0.      489.89114 583.38965  93.26286 988.71106\n",
      " 859.4125  770.53644   0.        0.      783.7819  788.2409    0.\n",
      "   0.        0.      449.82172 788.37427], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[  0.      601.1799  970.8447    0.        0.       71.13284 748.1327\n",
      " 489.89114 489.84494 895.09766 783.75903  78.30095 489.75735   0.\n",
      " 676.9833  694.7423  690.2239  391.69974 391.65683   0.        0.\n",
      " 801.53986 489.84686 801.47516 525.4669  770.8113    0.      489.93134\n",
      " 694.81726 614.44165   0.      489.77795], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[601.1958  150.90373 694.84644 988.7511  186.82056   0.      614.3992\n",
      "   0.      578.94574   0.      895.2778  988.6023  204.68936   0.\n",
      " 262.73373 222.37077   0.      298.26657   0.      614.4343    0.\n",
      " 489.8769  676.9911  204.55373   0.      151.04034 116.15755 373.8716\n",
      " 654.47314 374.04486 316.0223  449.47464], shape=(32,), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ede14c7dc2d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                 \u001b[0mcurrent_state_action_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[0mcurrent_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_state_action_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m--> 385\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    386\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    438\u001b[0m       \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_RUNTIME_UNKNOWN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0m\u001b[0;32m    441\u001b[0m           inputs, initial_state, training, mask, row_lengths)\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[1;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mlast_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpu_gru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mgpu_gru_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[0mlast_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandard_gru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnormal_gru_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m       last_output, outputs, new_h, runtime = gru_with_backend_selection(\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_gru\u001b[1;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m   last_output, outputs, new_states = K.rnn(\n\u001b[0m\u001b[0;32m    576\u001b[0m       \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m       \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minit_h\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4358\u001b[1;33m       final_outputs = control_flow_ops.while_loop(\n\u001b[0m\u001b[0;32m   4359\u001b[0m           \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4360\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2733\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2734\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2735\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2736\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2737\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[0;32m   4342\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mta\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_ta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4343\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4344\u001b[1;33m         output, new_states = step_function(current_input,\n\u001b[0m\u001b[0;32m   4345\u001b[0m                                            tuple(states) + tuple(constants))\n\u001b[0;32m   4346\u001b[0m         \u001b[0mflat_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[0;32m    566\u001b[0m                                                             axis=1)\n\u001b[0;32m    567\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_z\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrecurrent_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrecurrent_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m     \u001b[0mhh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_h\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrecurrent_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   3641\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Sigmoid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3642\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3643\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DevelopmentTools\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   8916\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8917\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8918\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   8919\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Sigmoid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8920\u001b[0m         tld.op_callbacks, x)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### fixed version\n",
    "\n",
    "\n",
    "print(f\"Training from ep {start_ep}\")\n",
    "for ep in range(start_ep, num_episode+start_ep):\n",
    "    \n",
    "    \n",
    "    ######## training cache  ############\n",
    "    ######################################\n",
    "\n",
    "    episode_reward = []\n",
    "    \n",
    "\n",
    "    ######## load episode data ############\n",
    "    ######################################\n",
    "    random_idx = np.random.randint(low=1, high = 160000)\n",
    "    data_slice =  train_data[:,:,random_idx+1:]/train_data[:,:,random_idx+20,None] # todo: +20 is hard coded to normalize the trade start pric\n",
    "    max_drawn = np.max(np.abs(np.diff(data_slice[:,0,:33],axis=1).ravel())) \n",
    "    if max_drawn>0.005:\n",
    "        # too volatile or cover two days...\n",
    "        continue\n",
    "        \n",
    "    env = trade_env(data =data_slice)\n",
    "    \n",
    "    ######## modify environment for small episode exploration ############\n",
    "    ######################################################################\n",
    "    if prob_of_smaller_interval>np.random.rand(1)[0] or ep<exploring_state_boundary:\n",
    "        \n",
    "        env.time_remain = np.random.choice([2,3,4])\n",
    "    else:\n",
    "        env.time_remain = 10\n",
    "        \n",
    "    current_state = env.start()\n",
    "    is_full_episode = True if env.time_remain ==10 else False\n",
    "    \n",
    "    \n",
    "    ######## exploration-stage and epsilon greedy  ############\n",
    "    ##########################################################\n",
    "    while True:\n",
    "        time_elapsed+=1\n",
    "        if time_elapsed%update_target ==0:\n",
    "                target_model.set_weights(main_model.get_weights())\n",
    "     \n",
    "        if ep< exploring_state_sub_opt or epsilon>np.random.rand(1)[0]:\n",
    "            action = np.random.choice(num_of_action)\n",
    "           \n",
    "        else:\n",
    "            action = tf.argmax(main_model(current_state,training = False),axis=1).numpy()[0]\n",
    "            \n",
    "           \n",
    "        \n",
    "        next_state, reward, end_episode = env.step(action)\n",
    "        \n",
    "\n",
    "        \n",
    "        action_history.append(action)\n",
    "        reward_history.append(reward)\n",
    "        state_history.append(current_state)\n",
    "        state_next_history.append(next_state)\n",
    "        done_history.append(end_episode)\n",
    "        episode_reward.append(reward)\n",
    "        \n",
    "        ######## train in the experience-replay buffer  ############\n",
    "        ##########################################################\n",
    "        \n",
    "        if  len(action_history)>= batch_size and time_elapsed%update_after_action==0:\n",
    "        \n",
    "            indices = np.random.choice(np.arange(len(action_history)),batch_size)\n",
    "            state_sample = state_sampler(state_history, indices)\n",
    "            state_next_sample = state_sampler(state_next_history, indices)\n",
    "            reward_sample = np.array(reward_history)[indices]\n",
    "            action_sample = np.array(action_history)[indices]\n",
    "            done_sample = np.array(done_history)[indices]\n",
    "\n",
    "            future_state_action_val = target_model.predict(state_next_sample)\n",
    "            future_state_action_val[np.isnan(future_state_action_val)] = 0 # this is for the terminal state (nans)\n",
    "            future_reward = tf.reduce_max(future_state_action_val,axis=1)\n",
    "           \n",
    "            G = reward+gamma*future_reward\n",
    "            mask = tf.one_hot(action_sample,num_of_action)\n",
    "          \n",
    "            \n",
    "#             print(f\"Act pre:{tf.reduce_sum(tf.multiply(main_model(state_sample),mask),axis=1)}\")\n",
    "            with tf.GradientTape() as tape:\n",
    "                \n",
    "                current_state_action_val = main_model(state_sample)\n",
    "                current_reward = tf.reduce_sum(tf.multiply(current_state_action_val,mask),axis=1)\n",
    "        \n",
    "                loss = loss_function(G, current_reward)  \n",
    "                grad = tape.gradient(loss, main_model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grad, main_model.trainable_variables))\n",
    "#             print(f\"Act target:{G}\")\n",
    "#             print(f\"Act post:{tf.reduce_sum(tf.multiply(main_model(state_sample),mask),axis=1)}\")\n",
    "\n",
    "                \n",
    "                \n",
    "        ######## set_state, clear buffer, and end episode  ############\n",
    "        ##########################################################     \n",
    "        current_state = next_state\n",
    "        if len(action_history)>max_buffer_length:\n",
    "            del action_history[:1]\n",
    "            del state_history[:1]\n",
    "            del state_next_history[:1]\n",
    "            del done_history[:1]\n",
    "            del reward_history[:1]\n",
    "        \n",
    "        \n",
    "        if end_episode:\n",
    "            if ep%100 ==0:\n",
    "                print(ep)\n",
    "            \n",
    "            break\n",
    " \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb25f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(pnl)\n",
    "np.mean(pnl)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ef45a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c9c8b299d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(TWAP)\n",
    "plt.plot(reward_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(model_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ccca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(TWAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_model.save(\"13k_trace3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8c504",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d769c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reward_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1373bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_curve = np.array(reward_curve)\n",
    "r = pd.DataFrame(reward_curve[reward_curve>99.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f49a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.rolling(1500).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c2102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:quant] *",
   "language": "python",
   "name": "conda-env-quant-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
